{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVFNeto/Inteligence-Fake-News-Detecter/blob/main/Fake_News_Detecter_7_0_5_1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECvrRC0qAyvz"
      },
      "source": [
        "#Descrição do projeto na utilização da IA para a materia de mesmo nome\n",
        "\n",
        "Aluno: João Vitor Ferreira Neto\n",
        "\n",
        "GTI 6° Periodo\n",
        " \n",
        "Professor: Carlos Silvio Gomes Junior\n",
        "\n",
        "Essa IA será capaz de identificar fake news, futuramente testarei ela em redes sociais, mas no momento estou treinando ela por um banco de dados do Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWKaPHFb86ZB"
      },
      "source": [
        "### FAKE NEWS DETECTER v. 7.0.5.1\n",
        "\n",
        "Criação e direitos autorais de:  *João Vitor Ferreira Neto e Maria da Graça Marques Andrade*\n",
        "\n",
        "Email Pessoal: carryonlink@gmail.com\n",
        "\n",
        "Email Educacional: joao.vitor1@estudante.ifgoiano.edu.br"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NVhVMUE18R4B"
      },
      "outputs": [],
      "source": [
        "#Importando as bibliotecas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlDpHkLTAaAf",
        "outputId": "5f3fa73f-aa17-41b6-e332-c49d84d8cbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "nltk.download('stopwords') #stopwords são conjunções/palavras que não serão incluidas na nossa IA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G59Teh_NApQs"
      },
      "outputs": [],
      "source": [
        "#introduzindo kaggle\n",
        "\n",
        "train = '/content/drive/MyDrive/Colab Notebooks/train.csv'\n",
        "\n",
        "#data base\n",
        "db = pd.read_csv(train, encoding='utf8' )\n",
        "\n",
        "db.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "laDxxj6ogoRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed41ea2-8c4a-48f4-db9a-f13ef32c7ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "title     0\n",
              "author    0\n",
              "text      0\n",
              "label     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#verificando nularidade\n",
        "\n",
        "db.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bif6_HU6hFEe"
      },
      "outputs": [],
      "source": [
        "#retirando nularidade\n",
        "db.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kxEj834jhU72"
      },
      "outputs": [],
      "source": [
        "#Juntando os campos\n",
        "\n",
        "db['all']=db['title']+' '+db['author']+' '+db['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rixpew6Kh_yp"
      },
      "outputs": [],
      "source": [
        "#verificando a junção do campos\n",
        "\n",
        "pd.options.display.max_colwidth = 150 #tamanho total da coluna \n",
        "\n",
        "print(db['all'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NxhVNH2cim5k"
      },
      "outputs": [],
      "source": [
        "#Steming\n",
        "\n",
        "ps = PorterStemmer() #trás a primitiva da palavra\n",
        "\n",
        "def stemming_tokenizer(db): #metodo de tokenização\n",
        "\n",
        "  words= re.sub(r\"[^A-Za-z0-9\\-]\", \" \", db).lower().split()\n",
        "  words= [ps.stem(word) for word in words if not words in stopwords.words('portuguese')]\n",
        "  words= ' '.join(words)\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3_euwxB70vaU"
      },
      "outputs": [],
      "source": [
        "db['features'] = db['all'].apply(stemming_tokenizer) #chamando metodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvX-OahI0_ri"
      },
      "outputs": [],
      "source": [
        "print(db['features'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gSavZxXxDMak"
      },
      "outputs": [],
      "source": [
        "#separando features e labels\n",
        "x= db['features'].values\n",
        "y= db['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFyFFyPVDmBY"
      },
      "outputs": [],
      "source": [
        "#convertendo de texto para num\n",
        "\n",
        "#porque?, simples, o modelo não entende um monte de palavras, ele entende numeros\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = vectorizer.transform(x)"
      ],
      "metadata": {
        "id": "qr6vGjvZFeI_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 42)"
      ],
      "metadata": {
        "id": "rzTwoGjZF3Fh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando o Zé Binario (nome da minha IA)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "2-xgCp8IG2mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Previsão\n",
        "\n",
        "pred = lr.predict(x_test)\n",
        "\n",
        "acc = accuracy_score(y_test, pred)\n",
        "\n",
        "f'Acurácia: {acc * 100:.2f}'\n",
        "\n",
        "#primeiro teste = 96.25%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eIy7jyyvHXsr",
        "outputId": "3a09d3f4-be86-4310-8cea-f1b84e6410da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Acurácia: 96.25'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "12xf6QRIrJvQxCdsR75lBTsgCyavFbgro",
      "authorship_tag": "ABX9TyPeG/KnwziLASPmqvHD3Z6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}